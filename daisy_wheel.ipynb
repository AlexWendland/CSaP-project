{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\wendlanda\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "#ALWAYS RUN FIRST!\n",
    "\n",
    "#Import libraries and packages. Don't worry about the warning if running it on windows, so far not hit an issue. (yn)\n",
    "\n",
    "import re\n",
    "from pylab import *\n",
    "import csv\n",
    "import psycopg2\n",
    "import spacy\n",
    "spacy.load('en')\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from gensim import corpora\n",
    "from datetime import datetime\n",
    "import pickle\n",
    "import gensim\n",
    "import os\n",
    "\n",
    "#Set the names of the files in which you want to save data, these will all be in the data file.\n",
    "\n",
    "affiliation_data_name = 'daisy_wheel_affiliation_data'\n",
    "department_data_name = 'daisy_wheel_department_data'\n",
    "meeting_data_name = 'daisy_wheel_meetings'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to access CRM CSaP database ...\n",
      "... data downloaded and saved to disk.\n"
     ]
    }
   ],
   "source": [
    "#Extract the data from the CRM. Don't run if you have an up to date copy of the CRM.\n",
    "\n",
    "try:\n",
    "    \n",
    "    #Opens connection to the CRM asks for peoples name and description.\n",
    "    #Output rows for row in rows row[0] - first name, row[1] - second name, row[2] - description.\n",
    "    \n",
    "    print(\"Trying to access CRM CSaP database ...\")\n",
    "    \n",
    "    conn = psycopg2.connect(SERVER_DATA)\n",
    "    \n",
    "    cur = conn.cursor()\n",
    "    \n",
    "    cur.execute(\"\"\"SELECT\n",
    "    person.id,\n",
    "    person.first_name,\n",
    "    person.last_name,\n",
    "    organization.name\n",
    "    FROM people_person as person\n",
    "    INNER JOIN\n",
    "    organizations_personorganizationrole\n",
    "    ON\n",
    "    organizations_personorganizationrole.person_id = person.id\n",
    "    INNER JOIN\n",
    "    organizations_organization as organization\n",
    "    ON\n",
    "    organization.id = organizations_personorganizationrole.organization_id\n",
    "    ;\n",
    "    \"\"\")\n",
    "    rows = cur.fetchall()\n",
    "\n",
    "    #Saves data to the file called above.\n",
    "    \n",
    "    with open(os.getcwd() + '\\data\\\\' + affiliation_data_name +'.csv','w+',newline ='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for row in rows:\n",
    "            wr.writerow([str(row[0]), row[1].encode('utf-8'), row[2].encode('utf-8'), row[3].encode('utf-8')])\n",
    "    \n",
    "    cur.execute(\"\"\"SELECT\n",
    "    people_policyfellowshipschedule.date,\n",
    "    fellow.id,\n",
    "    fellow.first_name,\n",
    "    fellow.last_name,\n",
    "    academic.id,\n",
    "    academic.first_name,\n",
    "    academic.last_name\n",
    "    FROM people_policyfellowshipschedule_people\n",
    "    JOIN people_person as academic ON people_policyfellowshipschedule_people.person_id = academic.id\n",
    "    JOIN people_policyfellowshipschedule ON people_policyfellowshipschedule_people.policyfellowshipschedule_id = people_policyfellowshipschedule.id\n",
    "    JOIN people_policyfellowship ON people_policyfellowshipschedule.policy_fellowship_id = people_policyfellowship.id\n",
    "    JOIN people_person as fellow ON people_policyfellowship.policy_fellow_id = fellow.id\n",
    "    ;\n",
    "    \"\"\")\n",
    "    \n",
    "    rows = cur.fetchall()\n",
    "    \n",
    "    #Saves data to the file called above.\n",
    "    \n",
    "    with open(os.getcwd() + '\\data\\\\' + meeting_data_name +'.csv','w+',newline ='') as myfile:\n",
    "        wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "        for row in rows:\n",
    "            wr.writerow([row[0].strftime(\"%Y-%m-%d\"), str(row[1]), row[2].encode('utf-8'), row[3].encode('utf-8'), str(row[4]), row[5].encode('utf-8'), row[6].encode('utf-8')])\n",
    "    print(\"... data downloaded and saved to disk.\")\n",
    "    \n",
    "except Exception as e:\n",
    "    \n",
    "    print(e)\n",
    "    \n",
    "    #If server isn't online this collects data from the save file.\n",
    "    \n",
    "    print(\"... can't access server, is the tunnel set up? Can continue on previously saved data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Functions for cleaning the text and getting it ready to be procced.\n",
    "\n",
    "#Gets rid of HTML tags and end of line markers.\n",
    "#Input: String of text from CRM or internet.\n",
    "#Output: Cleaned up string of text without HTML tags or end of line markers.\n",
    "\n",
    "def clean_text(text):\n",
    "    \n",
    "    #Removes HTML tags.\n",
    "    \n",
    "    clean = re.compile('<.*?>')\n",
    "    temp_text = re.sub(clean, '', text)\n",
    "    \n",
    "    #Removes rouge utf-8 code.\n",
    "    \n",
    "    clean = re.compile('\\\\\\\\x\\w\\w')\n",
    "    temp_text = re.sub(clean, '', temp_text)\n",
    "    \n",
    "    clean = re.compile('\\\\\\\\x\\w')\n",
    "    temp_text = re.sub(clean, '', temp_text)\n",
    "    \n",
    "    #Removes end of line indicators and other junk.\n",
    "    \n",
    "    tags = ['\\\\r','\\\\n','/','\\\\t','\\\\']\n",
    "    \n",
    "    for tag in tags:\n",
    "        temp_text = temp_text.replace(tag,'')\n",
    "    \n",
    "    return temp_text\n",
    "\n",
    "#Tokenizes text, seperates it into a string of words and grammar.\n",
    "#Input: A string of text.\n",
    "#Output: A list of words and grammar in order all in lower case.\n",
    "\n",
    "parser = English()\n",
    "\n",
    "def tokenize(text):\n",
    "    lda_tokens = []\n",
    "    tokens = parser(text)\n",
    "    for token in tokens:\n",
    "        if token.orth_.isspace():\n",
    "            continue\n",
    "        elif token.like_url:\n",
    "            lda_tokens.append('URL')\n",
    "        elif token.orth_.startswith('@'):\n",
    "            lda_tokens.append('SCREEN_NAME')\n",
    "        else:\n",
    "            lda_tokens.append(token.lower_)\n",
    "    return lda_tokens\n",
    "\n",
    "#Lemmatiser, this finds the root word (i.e. depluralises).\n",
    "#Input: a token, i.e. a single word or grammar.\n",
    "#Output: a lemma which is the base of the word and association \n",
    "\n",
    "def get_lemma(word):\n",
    "    return WordNetLemmatizer().lemmatize(word)\n",
    "    \n",
    "#Prepares text for the analysis, tokenizes texts, gets rid of words length less than 4 and filters out non-useful words then\n",
    "#Lemmatisers the text.\n",
    "#Input: A string of text you want to analysis.\n",
    "#Output: A list of Lemmas of the meaningful words.\n",
    "\n",
    "def prepare_text_for_lda(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [tok[0] for tok in nltk.pos_tag(tokens) if tok[1][0] == 'N']\n",
    "    tokens = [token for token in tokens if len(token) > 4]\n",
    "    en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if token not in en_stop]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens\n",
    "\n",
    "#Specialised version of the above function for organisations.\n",
    "#Input: A string of text you want to analysis.\n",
    "#Output: A list of Lemmas of the meaningful words.\n",
    "\n",
    "def perpare_organisation(text):\n",
    "    tokens = tokenize(text)\n",
    "    tokens = [token for token in tokens if len(token) > 2]\n",
    "    en_stop = set(nltk.corpus.stopwords.words('english'))\n",
    "    tokens = [token for token in tokens if (token not in en_stop)]\n",
    "    tokens = [get_lemma(token) for token in tokens]\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trying to load up data ...\n",
      "... data successfully uploaded.\n"
     ]
    }
   ],
   "source": [
    "#This uploads the person data into the program from the file, cleaning the data whilst it does it.\n",
    "\n",
    "print(\"Trying to load up data ...\")\n",
    "\n",
    "affiliations = []\n",
    "meetings = []\n",
    "\n",
    "try:\n",
    "    with open(os.getcwd() + '\\data\\\\' + affiliation_data_name +'.csv', 'r') as csvfile:\n",
    "        dump = list(csv.reader(csvfile))\n",
    "        for row in dump:\n",
    "            affiliations.append([int(row[0]), clean_text(row[1][2:-1]), clean_text(row[2][2:-1]), clean_text(row[3][2:-1])])\n",
    "    \n",
    "    with open(os.getcwd() + '\\data\\\\' + meeting_data_name +'.csv', 'r') as csvfile:\n",
    "        dump = list(csv.reader(csvfile))\n",
    "        for row in dump:\n",
    "            meetings.append([datetime.strptime(row[0],'%Y-%m-%d'),int(row[1]),clean_text(row[2][2:-1]),clean_text(row[3][2:-1]),int(row[4]),clean_text(row[5][2:-1]),clean_text(row[6][2:-1])])\n",
    "    \n",
    "    print(\"... data successfully uploaded.\")\n",
    "    \n",
    "except:\n",
    "        \n",
    "    print(\".. no back up data, please connect to server.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to the Diasy Wheel Tool. To generate the daisy wheel data we are going to need your help!\n",
      "\n",
      "If this is not the first time your running me, you might want to make a copy of the input/output files you used last time. Otherwise you might lose the data from then.\n",
      "\n",
      "Please input the first date you want to record meetings from (YYYY-MM-DD):2018-12-01\n",
      "Please input the last date you want to record meetings to (YYYY-MM-DD):2018-12-31\n",
      "\n",
      "There where 20 between those dates.\n",
      "\n",
      "Ok, got those meetings. Next we need to sort the Academics into their groups. I will just print the list of affiliations they have into a file in the inputs folder called academic_affiliations. If you go there, you can assign each affiliation a Primary and Secondary tag i.e. which department then school they are in. Any cell left blank I will assume goes in other. There is an example on the top line, do not worry this line will not get used.\n",
      "\n",
      "Once your done filling that in just hit enter.\n",
      "\n",
      "Ok got that. I am going to run you through your tag system as it currently stands.\n",
      "\n",
      "university\n",
      "     - department\n",
      "     - school\n",
      "\n",
      "other\n",
      "     - industry\n",
      "     - other\n",
      "\n",
      "Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: y\n",
      "\n",
      "Great! I am just going to try and match academics to their tag, if they have no affiliation on the database I will add them as other. If they have multiple tags I will try to add the most frequently occuring one.\n",
      "\n",
      "Ok, created it. If you look in the file called academic_tagged_people in the inputs folder you can see how I have allocated the tags. If there is anything you are unhappy about just change the primary and secondary tag. Let me know when you are done by hitting enter.\n",
      "\n",
      "Ok got that. I am going to run you through your tag system as it currently stands.\n",
      "\n",
      "university\n",
      "     - school\n",
      "     - department\n",
      "\n",
      "other\n",
      "     - industry\n",
      "     - other\n",
      "\n",
      "Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: y\n",
      "\n",
      "Ok, That is the Academics sorted now the fellows. I will just print the list of affiliations they have into a file in the inputs folder called fellow_affiliations. If you go there, you can assign each affiliation a Primary and Secondary tag i.e. which sector then sub-sector they are in. Any cell left blank I will assume goes in other. There is an example on the top line, do not worry this line will not get used.\n",
      "\n",
      "Once your done filling that in just hit enter.\n",
      "\n",
      "Ok got that. I am going to run you through your tag system as it currently stands.\n",
      "\n",
      "whitehall\n",
      "     - home office\n",
      "     - royal\n",
      "\n",
      "london\n",
      "     - newham\n",
      "\n",
      "Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: y\n",
      "\n",
      "Great! I am just going to try and match fellows to their tag, if they have no affiliation on the database I will add them as other. If they have multiple tags I will try to add the most frequently occuring one.\n",
      "\n",
      "Ok, created it. If you look in the file called fellow_tagged_people in the inputs folder you can see how I have allocated the tags. If there is anything you are unhappy about just change the primary and secondary tag. Let me know when you are done by hitting enter.\n",
      "\n",
      "Ok got that. I am going to run you through your tag system as it currently stands.\n",
      "\n",
      "london\n",
      "     - newham\n",
      "\n",
      "whitehall\n",
      "     - home office\n",
      "     - royal\n",
      "\n",
      "Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: y\n",
      "\n",
      "Awesome, I have everything I need from you now it is up to me.\n",
      "\n",
      "The data should be in the outputs folder under the name daisy_wheel_data_2018_12_01_to_2018-12-31 hope this is all ok. Have a great day!\n"
     ]
    }
   ],
   "source": [
    "##\n",
    "## After uploading the data run this for the main daisy wheel tool.\n",
    "##\n",
    "\n",
    "#Filters the meetins by year.\n",
    "#Input: List of all meetings, start_date and end_date.\n",
    "#Output: List of meetings occuring after start_date and before end_date inclusive.\n",
    "\n",
    "def filter_meetings(meetings, start_date, end_date):\n",
    "    new_meetings = []\n",
    "    for meeting in meetings:\n",
    "        if meeting[0] >= start_date and meeting[0] <= end_date:\n",
    "            new_meetings.append(meeting)\n",
    "    \n",
    "    return new_meetings\n",
    "\n",
    "#Given a list of people and affiliations edits the list of people and attaches their affiliations attached.\n",
    "#Input: A list of people [id,first_name,last_name] and a list of possible affiliations.\n",
    "#Output: Empty but changes people to affiliated_peple [id,first_name,last_name, affiliations].\n",
    "\n",
    "def affiliate_people(people, affiliations):\n",
    "    for person in people:\n",
    "        persons_affiliations = []\n",
    "        for affiliation in affiliations:\n",
    "            if person[0] == affiliation[0] and affiliation[3] not in persons_affiliations:\n",
    "                persons_affiliations.append(affiliation[3])\n",
    "        persons_affiliations.sort()\n",
    "        person.append(persons_affiliations)\n",
    "\n",
    "#Given a list of affiliated people returns a list of affiliations attached to those people.\n",
    "#Input: List of people with affiliations [id,first_name,last_name, affiliations].\n",
    "#Output: List of affiliations that those people belong to without repeats.\n",
    "\n",
    "def get_affiliation_list(affiliated_people):\n",
    "    organisations = []\n",
    "    for person in affiliated_people:\n",
    "        for affiliation in person[3]:\n",
    "            if affiliation not in organisations:\n",
    "                organisations.append(affiliation)\n",
    "    organisations.sort()\n",
    "    return organisations\n",
    "\n",
    "#Returns a list of people attached to the meetings without repeats, either Academics or fellows.\n",
    "#Input: The list of meetings, num = 0 for fellows or num = 1 for academics.\n",
    "#Ouput: List of people person[0] - id, person [1] - first name and person[2] - last name.\n",
    "\n",
    "def get_people(meetings, num):\n",
    "    people = []\n",
    "    for meeting in meetings:\n",
    "        person = [meeting[num*3+1],meeting[num*3+2],meeting[num*3+3]]\n",
    "        if person not in people:\n",
    "            people.append(person)\n",
    "    return people\n",
    "\n",
    "#Creates an csv file with list of aggiliations in it.\n",
    "#Input: A string file_name and a list of affiliations.\n",
    "#Output: Empty but creates a csv file in input\\file_name, also if the user has that file open prompts them to close it.\n",
    "\n",
    "def create_affiliation_csv(file_name,affiliation_list):\n",
    "    while True:\n",
    "        try:\n",
    "            with open(os.getcwd() + '\\input\\\\' + file_name +'.csv','w+',newline ='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow(['Affiliation', 'Primary Tag', 'Secondary Tag'])\n",
    "                wr.writerow(['Centre for Science and Policy', 'University of Cambridge', 'Centre of Science and Policy', 'This is an example and will not be added to the actual affiliations list'])\n",
    "                for affiliation in affiliation_list:\n",
    "                    wr.writerow([affiliation])\n",
    "            break           \n",
    "        except:\n",
    "            input('Please close ' + file_name + ' when you have done so press enter.')\n",
    "            print('')\n",
    "\n",
    "#Reads a csv file with the user input of the tags associated to affiliations.\n",
    "#Input: A string file_name with the file name.\n",
    "#Output: The sorting dictionary that assoicates affiliations with the tags and a dictionary of tags where the primary tag leads \n",
    "#to a list of secondary tags.\n",
    "        \n",
    "def export_affiliation_csv(file_name):\n",
    "    sorting_dictionary = {}\n",
    "    tag_dictionary = {}\n",
    "    with open(os.getcwd() + '\\input\\\\' + file_name +'.csv', 'r') as csvfile:\n",
    "        dump = list(csv.reader(csvfile))\n",
    "        for i in range(2,len(dump)):\n",
    "            row = dump[i].copy()\n",
    "            if row[1] == '':\n",
    "                row[1] = 'other'\n",
    "            else:\n",
    "                row[1] = row[1].lower()\n",
    "            if row[2] == '':\n",
    "                row[2] = 'other'\n",
    "            else:\n",
    "                row[2] = row[2].lower()\n",
    "            sorting_dictionary[row[0]] = [row[1], row[2]]\n",
    "            if row[1] not in tag_dictionary.keys():\n",
    "                tag_dictionary[row[1]] = [row[2]]\n",
    "            else:\n",
    "                if row[2] not in tag_dictionary[row[1]]:\n",
    "                    tag_dictionary[row[1]].append(row[2])\n",
    "    return sorting_dictionary, tag_dictionary\n",
    "\n",
    "#Finds most numerous tag accosiated to their affiliations then writes a list of people with tags and affiliations.\n",
    "#Input: List of affiliated people [id,first_name,last_name, affiliations], a string file_name and lastly the sorting and tag \n",
    "#dictionary.\n",
    "#Output: Empty but writes a csv file.\n",
    "\n",
    "def create_people_csv(affiliated_people,file_name,sorting_dictionary):\n",
    "    affiliated_people.sort(key=lambda person: person[2])\n",
    "    people_output = []\n",
    "    for person in affiliated_people:\n",
    "        new_person = [person[0],person[1],person[2]]\n",
    "        if len(person[3]) == 0:\n",
    "            new_person.append('other')\n",
    "            new_person.append('other')\n",
    "        elif len(person[3]) == 1:\n",
    "            new_person.extend(sorting_dictionary[person[3][0]])\n",
    "            new_person.append(person[3][0])\n",
    "        else:\n",
    "            tags = []\n",
    "            for affiliation in person[3]:\n",
    "                found = False\n",
    "                this_tag = sorting_dictionary[affiliation].copy()\n",
    "                for tag in tags:\n",
    "                    if tag[0] == this_tag:\n",
    "                        tag.append(affiliation)\n",
    "                        found = True\n",
    "                        break\n",
    "                if not found:\n",
    "                    this_tag.append(affiliation)\n",
    "                    tags.append(this_tag)\n",
    "            tags.sort(key=len)\n",
    "            new_person.append(tags[0][0])\n",
    "            new_person.append(tags[0][1])\n",
    "            new_person.extend(person[3])\n",
    "        people_output.append(new_person)\n",
    "    while True:\n",
    "        try:\n",
    "            with open(os.getcwd() + '\\input\\\\' + file_name +'.csv','w+',newline ='') as myfile:\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow(['Person_ID', 'First Name', 'Second Name', 'Primary Tag', 'Secondary Tag', 'Affiliations:'])\n",
    "                for person in people_output:\n",
    "                    wr.writerow(person)\n",
    "            break\n",
    "        except:\n",
    "            input('Please close ' + file_name + ' when you have done so press enter.')\n",
    "            print('')\n",
    "\n",
    "#This function reads the User input from create_people_csv file and exports it to dictionaries for later use.\n",
    "#Input: A string file_name.\n",
    "#Output: Two dictionaries one which associates peoples id's as strings to their tags, associates primary tags to a list of\n",
    "#secondary tags.\n",
    "            \n",
    "def export_people_csv(file_name):\n",
    "    sorting_dictionary = {}\n",
    "    tag_dictionary = {}\n",
    "    with open(os.getcwd() + '\\input\\\\' + file_name +'.csv', 'r') as csvfile:\n",
    "        dump = list(csv.reader(csvfile))\n",
    "        for i in range(1,len(dump)):\n",
    "            row = dump[i].copy()\n",
    "            if row[3] == '':\n",
    "                row[3] = 'other'\n",
    "            else:\n",
    "                row[3] = row[3].lower()\n",
    "            if row[4] == '':\n",
    "                row[4] = 'other'\n",
    "            else:\n",
    "                row[4] = row[4].lower()\n",
    "            sorting_dictionary[row[0]] = [row[3], row[4]]\n",
    "            if row[3] not in tag_dictionary.keys():\n",
    "                tag_dictionary[row[3]] = [row[4]]\n",
    "            else:\n",
    "                if row[4] not in tag_dictionary[row[3]]:\n",
    "                    tag_dictionary[row[3]].append(row[4])\n",
    "    return sorting_dictionary, tag_dictionary\n",
    "\n",
    "#Tabulates the number of meetings between departments in Cambridge and the sectors in Policy and outputs the associated daisy\n",
    "#wheel data in a csv of the format specified.\n",
    "#Input: Academic dictionaries, fellow dictionaries, list of meetings and the string file_name to save it to.\n",
    "#Output: Empty but saves a CSV file with the above data.\n",
    "\n",
    "def output_daisy_wheel_data(academic_sorting_dictionary, academic_tag_dictionary, fellow_sorting_dictionary, fellow_tag_dictionary, meetings,file_name):\n",
    "    daisy_wheel_dictionary = {'meetings':{},'people':{}}\n",
    "    for fellow in get_people(meetings,0):\n",
    "        indicator = fellow_sorting_dictionary[str(fellow[0])][0] + '-/-' + fellow_sorting_dictionary[str(fellow[0])][1]\n",
    "        if indicator not in daisy_wheel_dictionary['people'].keys():\n",
    "            daisy_wheel_dictionary['people'][indicator] = 1\n",
    "            daisy_wheel_dictionary['meetings'][indicator] = 0\n",
    "        else:\n",
    "            daisy_wheel_dictionary['people'][indicator] += 1\n",
    "    for academic in get_people(meetings,1):\n",
    "        indicator = academic_sorting_dictionary[str(academic[0])][0] + '-/-' + academic_sorting_dictionary[str(academic[0])][1]\n",
    "        if indicator not in daisy_wheel_dictionary.keys():\n",
    "            daisy_wheel_dictionary[indicator] = {'meetings':0,'people':1}\n",
    "        else:\n",
    "            daisy_wheel_dictionary[indicator]['people'] += 1\n",
    "    for meeting in meetings:\n",
    "        fellow_indicator = fellow_sorting_dictionary[str(meeting[1])][0] + '-/-' + fellow_sorting_dictionary[str(meeting[1])][1]\n",
    "        academic_indicator = academic_sorting_dictionary[str(meeting[4])][0] + '-/-' + academic_sorting_dictionary[str(meeting[4])][1]\n",
    "        if fellow_indicator not in daisy_wheel_dictionary[academic_indicator].keys():\n",
    "            daisy_wheel_dictionary[academic_indicator][fellow_indicator] = 1\n",
    "        else:\n",
    "            daisy_wheel_dictionary[academic_indicator][fellow_indicator] += 1\n",
    "        daisy_wheel_dictionary[academic_indicator]['meetings'] += 1\n",
    "        daisy_wheel_dictionary['meetings'][fellow_indicator] += 1\n",
    "    while True:\n",
    "        try:\n",
    "            with open(os.getcwd() + '\\output\\\\' + file_name +'.csv','w+',newline ='') as myfile:\n",
    "                first_line = ['Primary Tag:','','','']\n",
    "                second_line = ['','Secondary Tag:','','']\n",
    "                third_line = ['','','Number of people:', '']\n",
    "                fourth_line = ['','','','Number of meetings:']\n",
    "                for fellow_primary_tag in fellow_tag_dictionary.keys():\n",
    "                    for fellow_secondary_tag in fellow_tag_dictionary[fellow_primary_tag]:\n",
    "                        fellow_indicator = fellow_primary_tag + '-/-' + fellow_secondary_tag\n",
    "                        first_line.append(fellow_primary_tag)\n",
    "                        second_line.append(fellow_secondary_tag)\n",
    "                        third_line.append(str(daisy_wheel_dictionary['people'][fellow_indicator]))\n",
    "                        fourth_line.append(str(daisy_wheel_dictionary['meetings'][fellow_indicator]))\n",
    "                wr = csv.writer(myfile, quoting=csv.QUOTE_ALL)\n",
    "                wr.writerow(first_line)\n",
    "                wr.writerow(second_line)\n",
    "                wr.writerow(third_line)\n",
    "                wr.writerow(fourth_line)\n",
    "                for academic_primary_tag in academic_tag_dictionary.keys():\n",
    "                    for academic_secondary_tag in academic_tag_dictionary[academic_primary_tag]:\n",
    "                        academic_indicator = academic_primary_tag + '-/-' + academic_secondary_tag\n",
    "                        row = [academic_primary_tag, academic_secondary_tag,str(daisy_wheel_dictionary[academic_indicator]['people']),str(daisy_wheel_dictionary[academic_indicator]['meetings'])]\n",
    "                        for fellow_primary_tag in fellow_tag_dictionary.keys():\n",
    "                            for fellow_secondary_tag in fellow_tag_dictionary[fellow_primary_tag]:\n",
    "                                fellow_indicator = fellow_primary_tag + '-/-' + fellow_secondary_tag\n",
    "                                if fellow_indicator in daisy_wheel_dictionary[academic_indicator].keys():\n",
    "                                    row.append(str(daisy_wheel_dictionary[academic_indicator][fellow_indicator]))\n",
    "                                else:\n",
    "                                    row.append('0')\n",
    "                        wr.writerow(row)\n",
    "            break\n",
    "        except:\n",
    "            input('Please close ' + file_name + ' when you have done so press enter.')\n",
    "\n",
    "#This is the daisy wheel tool. Walks the user through inputing the tag data and combines it all to output the daisy wheel data\n",
    "#in the form requested.\n",
    "#Input: The downloaded list of meeting and affiliations.\n",
    "#Output: Empty but creates a csv file with Diasy wheel data in.\n",
    "            \n",
    "def daisy_wheel_tool(meetings, affiliations):\n",
    "    print('Welcome to the Diasy Wheel Tool. To generate the daisy wheel data we are going to need your help!')\n",
    "    print('')\n",
    "    print('If this is not the first time your running me, you might want to make a copy of the input/output files you used last time. Otherwise you might lose the data from then.')\n",
    "    print('')\n",
    "    \n",
    "    #Get users time interval they want data from.\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            start_date = datetime.strptime(input('Please input the first date you want to record meetings from (YYYY-MM-DD):'),'%Y-%m-%d')\n",
    "            break\n",
    "        except:\n",
    "            print('Sorry, it looks like the date was in the wrong format. I need them YYYY-MM-DD, so the 14th January 2019 is 2019-01-14. Should we try again?')\n",
    "    \n",
    "    while True:\n",
    "        try:\n",
    "            end_date = datetime.strptime(input('Please input the last date you want to record meetings to (YYYY-MM-DD):'),'%Y-%m-%d')\n",
    "            break\n",
    "        except:\n",
    "            print('Sorry, it looks like the date was in the wrong format. I need them YYYY-MM-DD, so the 16th February 1993 is 1993-02-16. Should we try again?')\n",
    "    filtered_meetings = filter_meetings(meetings, start_date, end_date)\n",
    "    print('')\n",
    "    print('There where', len(filtered_meetings), 'between those dates.')\n",
    "    \n",
    "    #Let the user assign the tags to academics as they would like.\n",
    "    \n",
    "    print('')\n",
    "    print('Ok, got those meetings. Next we need to sort the Academics into their groups. I will just print the list of affiliations they have into a file in the inputs folder called academic_affiliations. If you go there, you can assign each affiliation a Primary and Secondary tag i.e. which department then school they are in. Any cell left blank I will assume goes in other. There is an example on the top line, do not worry this line will not get used.')\n",
    "    print('')\n",
    "    affiliated_academics = get_people(filtered_meetings,1)\n",
    "    affiliate_people(affiliated_academics,affiliations)\n",
    "    create_affiliation_csv('academic_affiliations',get_affiliation_list(affiliated_academics))\n",
    "    input('Once your done filling that in just hit enter.')\n",
    "    print('')\n",
    "    \n",
    "    #Check user is ok with there tag system, if not let them go back and change it.\n",
    "    \n",
    "    while True:\n",
    "        academic_sorting_dictionary, academic_tag_dictionary = export_affiliation_csv('academic_affiliations')\n",
    "        print('Ok got that. I am going to run you through your tag system as it currently stands.')\n",
    "        for primary_tag in academic_tag_dictionary.keys():\n",
    "            print('')\n",
    "            print(primary_tag)\n",
    "            for secondary_tag in academic_tag_dictionary[primary_tag]:\n",
    "                print('     -', secondary_tag)\n",
    "        print('')\n",
    "        responce = input('Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: ').lower()\n",
    "        print('')\n",
    "        if (responce == 'y') or (responce == 'yes') or (responce == 'yeah') or (responce == 'ye'):\n",
    "            break\n",
    "        input('Ok, feel free to change the document just hit enter when your done.')\n",
    "        print('')\n",
    "     \n",
    "    #Assign the affiliations to academics let the user review the process.\n",
    "    \n",
    "    print('Great! I am just going to try and match academics to their tag, if they have no affiliation on the database I will add them as other. If they have multiple tags I will try to add the most frequently occuring one.')\n",
    "    print('')\n",
    "    create_people_csv(affiliated_academics,'academic_tagged_people',academic_sorting_dictionary)\n",
    "    input('Ok, created it. If you look in the file called academic_tagged_people in the inputs folder you can see how I have allocated the tags. If there is anything you are unhappy about just change the primary and secondary tag. Let me know when you are done by hitting enter.')\n",
    "    print('')\n",
    "    \n",
    "    #Let the user review the current tag system.\n",
    "    \n",
    "    while True:\n",
    "        academic_sorting_dictionary, academic_tag_dictionary = export_people_csv('academic_tagged_people')\n",
    "        print('Ok got that. I am going to run you through your tag system as it currently stands.')\n",
    "        for primary_tag in academic_tag_dictionary.keys():\n",
    "            print('')\n",
    "            print(primary_tag)\n",
    "            for secondary_tag in academic_tag_dictionary[primary_tag]:\n",
    "                print('     -', secondary_tag)\n",
    "        print('')\n",
    "        responce = input('Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: ').lower()\n",
    "        print('')\n",
    "        if (responce == 'y') or (responce == 'yes') or (responce == 'yeah') or (responce == 'ye'):\n",
    "            break\n",
    "        input('Ok, feel free to change the document just hit enter when your done.')\n",
    "        print('')\n",
    "    \n",
    "    #Now move on to Fellows and do the same process again.\n",
    "    \n",
    "    print('Ok, That is the Academics sorted now the fellows. I will just print the list of affiliations they have into a file in the inputs folder called fellow_affiliations. If you go there, you can assign each affiliation a Primary and Secondary tag i.e. which sector then sub-sector they are in. Any cell left blank I will assume goes in other. There is an example on the top line, do not worry this line will not get used.')\n",
    "    print('')\n",
    "    affiliated_fellows = get_people(filtered_meetings,0)\n",
    "    affiliate_people(affiliated_fellows,affiliations)\n",
    "    create_affiliation_csv('fellow_affiliations',get_affiliation_list(affiliated_fellows))\n",
    "    input('Once your done filling that in just hit enter.')\n",
    "    print('')\n",
    "    \n",
    "    #Check user is ok with there tag system, if not let them go back and change it.\n",
    "    \n",
    "    while True:\n",
    "        fellow_sorting_dictionary, fellow_tag_dictionary = export_affiliation_csv('fellow_affiliations')\n",
    "        print('Ok got that. I am going to run you through your tag system as it currently stands.')\n",
    "        for primary_tag in fellow_tag_dictionary.keys():\n",
    "            print('')\n",
    "            print(primary_tag)\n",
    "            for secondary_tag in fellow_tag_dictionary[primary_tag]:\n",
    "                print('     -', secondary_tag)\n",
    "        print('')\n",
    "        responce = input('Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: ').lower()\n",
    "        print('')\n",
    "        if (responce == 'y') or (responce == 'yes') or (responce == 'yeah') or (responce == 'ye'):\n",
    "            break\n",
    "        input('Ok, feel free to change the document just hit enter when your done.')\n",
    "        print('')\n",
    "     \n",
    "    #Assign the affiliations to fellows let the user review the process.\n",
    "    \n",
    "    print('Great! I am just going to try and match fellows to their tag, if they have no affiliation on the database I will add them as other. If they have multiple tags I will try to add the most frequently occuring one.')\n",
    "    print('')\n",
    "    create_people_csv(affiliated_fellows,'fellow_tagged_people',fellow_sorting_dictionary)\n",
    "    input('Ok, created it. If you look in the file called fellow_tagged_people in the inputs folder you can see how I have allocated the tags. If there is anything you are unhappy about just change the primary and secondary tag. Let me know when you are done by hitting enter.')\n",
    "    print('')\n",
    "    \n",
    "    #Let the user review the current tag system.\n",
    "    \n",
    "    while True:\n",
    "        fellow_sorting_dictionary, fellow_tag_dictionary = export_people_csv('fellow_tagged_people')\n",
    "        print('Ok got that. I am going to run you through your tag system as it currently stands.')\n",
    "        for primary_tag in fellow_tag_dictionary.keys():\n",
    "            print('')\n",
    "            print(primary_tag)\n",
    "            for secondary_tag in fellow_tag_dictionary[primary_tag]:\n",
    "                print('     -', secondary_tag)\n",
    "        print('')\n",
    "        responce = input('Are you happy with this system of tags? If not you can go back change the file and I will upload it again. y/n: ').lower()\n",
    "        print('')\n",
    "        if (responce == 'y') or (responce == 'yes') or (responce == 'yeah') or (responce == 'ye'):\n",
    "            break\n",
    "        input('Ok, feel free to change the document just hit enter when your done.')\n",
    "        print('')\n",
    "    \n",
    "    #Generate the data spread sheet for the user.\n",
    "\n",
    "    print('Awesome, I have everything I need from you now it is up to me.')\n",
    "    print('')\n",
    "    data_name = 'daisy_wheel_data_' + start_date.strftime(\"%Y_%m_%d\") + '_to_' + end_date.strftime(\"%Y_%m_%d\")\n",
    "    output_daisy_wheel_data(academic_sorting_dictionary, academic_tag_dictionary, fellow_sorting_dictionary, fellow_tag_dictionary, filtered_meetings,data_name)\n",
    "    print('The data should be in the outputs folder under the name', data_name, 'hope this is all ok. Have a great day!')\n",
    "    \n",
    "#daisy_wheel_tool(meetings,affiliations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##\n",
    "## This is some old code for sorting peoples affiliations into tags. Most probably some good stuff here might might be slightly\n",
    "## out of date, used old pull request that didn't include ID numbers.\n",
    "##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is imported as a dictionary with the names of the departments as lables and further dictionary as objects linked.\n",
    "#This uploads the dictionary data into the program from the file, cleaning the data whilst it does it.\n",
    "\n",
    "def read_dictionary_file(file_name):\n",
    "    \n",
    "    print(\"Trying to load up dictionary \", file_name, \" ...\")\n",
    "\n",
    "    new_dictionary = {}\n",
    "\n",
    "    try:\n",
    "        with open(os.getcwd() + '\\data\\\\' + file_name +'.csv', 'r') as csvfile:\n",
    "            dump = list(csv.reader(csvfile))\n",
    "            dic_place = []\n",
    "            for row in dump:\n",
    "                new_name = clean_text(row[0][2:-1])\n",
    "                cur_dic = new_dictionary\n",
    "                if new_name == 'END_DIC':\n",
    "                    del dic_place[len(dic_place) - 1]\n",
    "                else:\n",
    "                    for name in dic_place:\n",
    "                        cur_dic = cur_dic[name]\n",
    "                    cur_dic[new_name] = {}\n",
    "                    dic_place.append(new_name)\n",
    "\n",
    "        print(\"... dictionary successfully created.\")\n",
    "        \n",
    "        return new_dictionary\n",
    "\n",
    "    except :\n",
    "        \n",
    "        print(\".. no dictionary data.\")\n",
    "\n",
    "SFD = read_dictionary_file(department_data_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorts people into 4 categories, Cambridge university people, Other university people, Other Cambirdge people and the rest.\n",
    "\n",
    "cambridge_other = []\n",
    "cambridge_university = []\n",
    "other_university = []\n",
    "other = []\n",
    "\n",
    "for person in affiliations:\n",
    "    affiliation = tokenize(person[2])\n",
    "    if 'cambridge' in affiliation:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            cambridge_university.append(person)\n",
    "        else:\n",
    "            cambridge_other.append(person)\n",
    "    elif 'cambridgeshire' in affiliation:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            cambridge_university.append(person)\n",
    "        else:\n",
    "            cambridge_other.append(person)\n",
    "    else:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            other_university.append(person)\n",
    "        else:\n",
    "            other.append(person)            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checks to see if the words appearing in the group name appears in the persons affilliation.\n",
    "#Input: two strings affil and group.\n",
    "#Output: Boolean based on if the inportant words from the group name appear in the persons affiliation.\n",
    "\n",
    "def is_in_group(affil,group):\n",
    "    affil_tokenized = perpare_organisation(affil)\n",
    "    for item in perpare_organisation(group):\n",
    "        if item not in affil_tokenized:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "#RECCURSIVE FUNCTION\n",
    "#Used to create a new dictionary which is a copy of the old one with the additional field people and count.\n",
    "#Input: A dictionary to copy.\n",
    "#Output: A copy of that dictionary with additional fields.\n",
    "\n",
    "def create_count(cur_dic):\n",
    "    count = {}\n",
    "    count['people'] = []\n",
    "    count['count'] = 0\n",
    "    \n",
    "    for key in cur_dic.keys():\n",
    "        count[key] = create_count(cur_dic[key])\n",
    "    \n",
    "    return count\n",
    "\n",
    "#RECCURSIVE FUNCTION\n",
    "#Used to search through out dictionary structure and find all groups which they could fit into.\n",
    "#Input: A dictionary cur_dic, the persons data and the name of the dictionaries used to get here dic_names.\n",
    "#Output: List of dictionary locations that would git the person.\n",
    "\n",
    "def sort_person(cur_dic, person, dic_names):\n",
    "    keys = cur_dic.keys()\n",
    "    possibilities = []\n",
    "    for group in keys:\n",
    "        new_list = dic_names.copy()\n",
    "        new_list.append(group)\n",
    "        if is_in_group(person[2],group):\n",
    "            possibilities.append(new_list)\n",
    "        possibilities += sort_person(cur_dic[group], person,new_list)\n",
    "    return possibilities\n",
    "\n",
    "#RECCURSIVE FUNCTION\n",
    "#Adds the person to the dictionary location specified by names.\n",
    "#Input: A dictionary, the location data of the dictionary, index of how far through you are and the person you want to add.\n",
    "#Output: Empty.\n",
    "\n",
    "def add_this(cur_dic, names, index, person):\n",
    "    if len(names) <= index:\n",
    "        cur_dic[\"people\"].append(person)\n",
    "    else:\n",
    "        add_this(cur_dic[names[index]],names, index + 1, person)\n",
    "    \n",
    "#RECCURSIVE FUNCTION\n",
    "#Sums the number of people in area of the dictionary, including lower layers.\n",
    "#Input: A dictionary to sum.\n",
    "#Output: The number of people in this dictionary\n",
    "    \n",
    "def sum_dic(cur_dic):\n",
    "    keys = [key for key in cur_dic.keys() if key not in ['people','count']]\n",
    "    for key in keys:\n",
    "        cur_dic['count'] += sum_dic(cur_dic[key])\n",
    "    cur_dic['count'] += len(cur_dic['people'])\n",
    "    return cur_dic['count']\n",
    "\n",
    "#Takes a list of people with their affiliations and sorts them according to the dictionary given.\n",
    "#Input: List of people with their affiliation in the 3rd entry of a list and a dictionary to sort them by.\n",
    "#Output: A copy of the given dictionary with additional entries at each layer containing the people that fit and the number of them.\n",
    "\n",
    "def sort_people(people, sort_dict):\n",
    "    \n",
    "    count = create_count(sort_dict)\n",
    "    \n",
    "    for person in people:\n",
    "\n",
    "        possibilities = sort_person(sort_dict, person, [])\n",
    "\n",
    "        if len(possibilities) == 0:\n",
    "            count[\"people\"].append(person)\n",
    "        elif len(possibilities) == 1:\n",
    "            add_this(count,possibilities[0],0,person)\n",
    "        else:\n",
    "            for set_1 in possibilities:\n",
    "                possibility_1 = set_1[len(set_1) - 1]\n",
    "                for set_2 in possibilities:\n",
    "                    possibility_2 = set_2[len(set_2) - 1]\n",
    "                    if possibility_1 == possibility_2:\n",
    "                        continue\n",
    "                    elif is_in_group(possibility_2,possibility_1):\n",
    "                        possibilities.remove(set_1)\n",
    "                        break\n",
    "            if len(possibilities) == 1:\n",
    "                add_this(count,possibilities[0],0,person)\n",
    "            else:\n",
    "                count[\"people\"].append(person)\n",
    "    \n",
    "    sum_dic(count)\n",
    "    \n",
    "    return count\n",
    "\n",
    "#Filters the meetins by year.\n",
    "#Input: List of all meetings, start_date and end_date.\n",
    "#Output: List of meetings occuring after start_date and before end_date inclusive.\n",
    "\n",
    "def filter_meetings(meetings, start_date, end_date):\n",
    "    new_meetings = []\n",
    "    for meeting in meetings:\n",
    "        if meeting[0] >= start_date and meeting[0] <= end_date:\n",
    "            new_meetings.append(meeting)\n",
    "    \n",
    "    return new_meetings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sorts the people from Cambridge University into departments.\n",
    "\n",
    "sorted_people = sort_people(cambridge_university, SFD)\n",
    "\n",
    "#Prints stats about the sorting procedure.\n",
    "\n",
    "print (\"PRINT HOW MANY PEOPLE ARE IN UNACCOUNTED FOR ORGANISATIONS\")\n",
    "unaccount_affiliations = [person[2] for person in sorted_people['people']]\n",
    "print ('TOTAL = ', len(sorted_people['people']))\n",
    "for affil in set(unaccount_affiliations):\n",
    "    print (affil, unaccount_affiliations.count(affil))\n",
    "\n",
    "total = 0\n",
    "    \n",
    "print (\"\")\n",
    "print (\"HOW MANY ARE IN EACH SCHOOL\")\n",
    "for school in SFD.keys():\n",
    "    print (school, sorted_people[school][\"count\"])\n",
    "    total += sorted_people[school][\"count\"]\n",
    "\n",
    "print(\"\")\n",
    "print('LOCATED AND IDENTIFIED = ', total)\n",
    "    \n",
    "print (\"\")\n",
    "print (\"HOW MANY ARE IN EACH FACULTY\")\n",
    "for school in SFD.keys():\n",
    "    for faculty in SFD[school].keys():\n",
    "        print (faculty, sorted_people[school][faculty][\"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "academics = []\n",
    "\n",
    "for meeting in [[meet[3],meet[4]] for meet in meetings]:\n",
    "    if meeting not in [academic[0] for academic in academics]:\n",
    "        academics.append([meeting,[person[2] for person in people if person[0] == meeting[0] and person[1] == meeting[1]]])    \n",
    "\n",
    "cambridge_other = []\n",
    "cambridge_university = []\n",
    "colleges = []\n",
    "other_university = []\n",
    "other = []\n",
    "\n",
    "for academic in academics:\n",
    "    affiliation = [word for affiliation in academic[1] for word in perpare_organisation(affiliation)]\n",
    "    data_saved = [academic[0][0],academic[0][1],academic[1],affiliation]\n",
    "    if 'cambridge' in affiliation:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            cambridge_university.append(data_saved)\n",
    "        elif 'college' in affiliation:\n",
    "            colleges.append(data_saved)\n",
    "        else:\n",
    "            cambridge_other.append(data_saved)\n",
    "    elif 'cambridgeshire' in affiliation:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            cambridge_university.append(data_saved)\n",
    "        elif 'college' in affiliation:\n",
    "            colleges.append(data_saved)\n",
    "        else:\n",
    "            cambridge_other.append(data_saved)\n",
    "    elif 'college' in affiliation:\n",
    "        colleges.append(data_saved)\n",
    "    else:\n",
    "        if 'uni' in affiliation or 'university' in affiliation or 'univ' in affiliation:\n",
    "            other_university.append(data_saved)\n",
    "        else:\n",
    "            other.append(data_saved)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
